{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pylab as pl #繪圖\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下來，我們將設置模型超參數，輸入層的大小設置為7，這意味著我們將有6個上下文神經元和1個輸入神經元，seq_length定義我們的輸入和目標序列的長度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "input_size = 7\n",
    "hidden_size = 6\n",
    "output_size = 1\n",
    "epochs = 300\n",
    "seq_length = 20 #輸入長度，RNN的序列，這數字來自於data要放入的長度\n",
    "lr = 0.1 #學習率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_time_steps = np.linspace(2, 10, seq_length + 1) #指定區間產生平均的數值，產生2~10共21個，畫圖區間使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2. ,  2.4,  2.8,  3.2,  3.6,  4. ,  4.4,  4.8,  5.2,  5.6,  6. ,\n",
       "        6.4,  6.8,  7.2,  7.6,  8. ,  8.4,  8.8,  9.2,  9.6, 10. ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.sin(data_time_steps) #轉sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.90929743,  0.67546318,  0.33498815, -0.05837414, -0.44252044,\n",
       "       -0.7568025 , -0.95160207, -0.99616461, -0.88345466, -0.63126664,\n",
       "       -0.2794155 ,  0.1165492 ,  0.49411335,  0.79366786,  0.96791967,\n",
       "        0.98935825,  0.85459891,  0.58491719,  0.22288991, -0.17432678,\n",
       "       -0.54402111])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.resize((seq_length + 1, 1))#調整成1行,21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.90929743],\n",
       "       [ 0.67546318],\n",
       "       [ 0.33498815],\n",
       "       [-0.05837414],\n",
       "       [-0.44252044],\n",
       "       [-0.7568025 ],\n",
       "       [-0.95160207],\n",
       "       [-0.99616461],\n",
       "       [-0.88345466],\n",
       "       [-0.63126664],\n",
       "       [-0.2794155 ],\n",
       "       [ 0.1165492 ],\n",
       "       [ 0.49411335],\n",
       "       [ 0.79366786],\n",
       "       [ 0.96791967],\n",
       "       [ 0.98935825],\n",
       "       [ 0.85459891],\n",
       "       [ 0.58491719],\n",
       "       [ 0.22288991],\n",
       "       [-0.17432678],\n",
       "       [-0.54402111]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在我們將建立訓練數據，其中x是輸入序列，y是目標序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.Tensor(data[:-1]).type(dtype), requires_grad=False)\n",
    "y = Variable(torch.Tensor(data[1:]).type(dtype), requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 說明Variable強大功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.],\n",
      "        [ 3.,  4.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable # torch 中 Variable 模块\n",
    "\n",
    "# 先生鸡蛋\n",
    "tensor = torch.FloatTensor([[1,2],[3,4]])\n",
    "# 把鸡蛋放到篮子里, requires_grad是参不参与误差反向传播, 要不要计算梯度\n",
    "variable = Variable(tensor, requires_grad=True)\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.],\n",
      "        [ 3.,  4.]])\n"
     ]
    }
   ],
   "source": [
    "print(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.5000)\n",
      "tensor(7.5000)\n"
     ]
    }
   ],
   "source": [
    "t_out = torch.mean(tensor*tensor)       # x^2\n",
    "v_out = torch.mean(variable*variable)   # x^2\n",
    "print(t_out)\n",
    "print(v_out)    # 7.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable計算時搭配computational graph，將所有反向傳播的結點連接起來，方便一次把梯度都計算出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_out.backward() \n",
    "#d(v_out)/d(variable) = 1/4*2*variable = variable/2\n",
    "#Tensor也可以計算，但是無法作backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5000,  1.0000],\n",
      "        [ 1.5000,  2.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(variable.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.],\n",
      "        [ 3.,  4.]])\n"
     ]
    }
   ],
   "source": [
    "#各種variable形式\n",
    "print(variable)  # Variable 形式\n",
    "print(variable.data)  # data 形式\n",
    "print(variable.data.numpy()) # numpy 形式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 說明Variable強大功能(結束)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.90929743],\n",
       "       [ 0.67546318],\n",
       "       [ 0.33498815],\n",
       "       [-0.05837414],\n",
       "       [-0.44252044],\n",
       "       [-0.7568025 ],\n",
       "       [-0.95160207],\n",
       "       [-0.99616461],\n",
       "       [-0.88345466],\n",
       "       [-0.63126664],\n",
       "       [-0.2794155 ],\n",
       "       [ 0.1165492 ],\n",
       "       [ 0.49411335],\n",
       "       [ 0.79366786],\n",
       "       [ 0.96791967],\n",
       "       [ 0.98935825],\n",
       "       [ 0.85459891],\n",
       "       [ 0.58491719],\n",
       "       [ 0.22288991],\n",
       "       [-0.17432678],\n",
       "       [-0.54402111]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "我們需要創建兩個權重矩陣，w1的大小（input_size，hidden_​​size）用於輸入到隱藏連接，而w2矩陣的大小（hidden_​​size，output_size）用於隱藏到輸出連接。使用具有零均值的正態分佈初始化權重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#初始化\n",
    "w1 = torch.FloatTensor(input_size, hidden_size).type(dtype)\n",
    "init.normal_(w1, 0.0, 0.4) # init.normal 舊版  mean=0.0, std=0.4 (低離散程度)\n",
    "w1 =  Variable(w1, requires_grad=True) #requires_grad=True 需要反向傳播\n",
    "w2 = torch.FloatTensor(hidden_size, output_size).type(dtype)\n",
    "init.normal_(w2, 0.0, 0.4) # init.normal 舊版 mean=0.0, std=0.3 (低離散程度)\n",
    "w2 = Variable(w2, requires_grad=True) #requires_grad=True 需要反向傳播\n",
    "# w1作為輸入，w2最為輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0576],\n",
       "        [-0.1682],\n",
       "        [ 0.0103],\n",
       "        [-0.1003],\n",
       "        [-0.0371],\n",
       "        [ 0.2416]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們現在可以定義forward方法，它將輸入向量，context_state為Autograd的結果，整合兩個權重矩陣作為參數。我們將通過將輸入向量與context_state向量連接來創建向量xh。我們在xh向量和權重矩陣w1之間執行點積，然後將tanh函數應用為非線性，這對於RNN而言比sigmoid更好。然後我們在新的context_state和權重矩陣w2之間執行另一個點積。我們想要預測連續值，所以我們在這個階段不應用任何非線性。\n",
    "\n",
    "請注意，context_state將用於在下一個時間步驟填充上下文神經元。這就是我們返回context_state向量以及網絡輸出的原因。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#context_state\n",
    "#Variable(torch.zeros((1, hidden_size)).type(dtype), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(input, context_state, w1, w2):\n",
    "  xh = torch.cat((input, context_state), 1) #將input與context_state做連接，並成為列(Row)呈現\n",
    "  context_state = torch.tanh(xh.mm(w1)) #先對w1作內積，相近的數值就接近，再轉換tanh收斂到-1~1\n",
    "  out = context_state.mm(w2) #再對w2做內積作為輸出\n",
    "  return  (out, context_state) #回傳context_state與out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.cat 快速說明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0177, -2.7853, -0.9333,  0.9257, -0.3836, -0.1517],\n",
       "        [ 0.3209,  1.3938,  1.5060, -0.5414,  0.2553, -0.3046],\n",
       "        [ 0.8174, -0.0053, -1.9132, -0.6616, -0.2398, -0.0526],\n",
       "        [-0.0380, -0.7001, -0.4254,  0.1148, -0.7466,  0.3746]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = torch.randn(4, 6)\n",
    "x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0177, -2.7853, -0.9333,  0.9257, -0.3836, -0.1517],\n",
       "        [ 0.3209,  1.3938,  1.5060, -0.5414,  0.2553, -0.3046],\n",
       "        [ 0.8174, -0.0053, -1.9132, -0.6616, -0.2398, -0.0526],\n",
       "        [-0.0380, -0.7001, -0.4254,  0.1148, -0.7466,  0.3746],\n",
       "        [-0.0177, -2.7853, -0.9333,  0.9257, -0.3836, -0.1517],\n",
       "        [ 0.3209,  1.3938,  1.5060, -0.5414,  0.2553, -0.3046],\n",
       "        [ 0.8174, -0.0053, -1.9132, -0.6616, -0.2398, -0.0526],\n",
       "        [-0.0380, -0.7001, -0.4254,  0.1148, -0.7466,  0.3746],\n",
       "        [-0.0177, -2.7853, -0.9333,  0.9257, -0.3836, -0.1517],\n",
       "        [ 0.3209,  1.3938,  1.5060, -0.5414,  0.2553, -0.3046],\n",
       "        [ 0.8174, -0.0053, -1.9132, -0.6616, -0.2398, -0.0526],\n",
       "        [-0.0380, -0.7001, -0.4254,  0.1148, -0.7466,  0.3746]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x_t, x_t, x_t), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0177, -2.7853, -0.9333,  0.9257, -0.3836, -0.1517, -0.0177,\n",
       "         -2.7853, -0.9333,  0.9257, -0.3836, -0.1517, -0.0177, -2.7853,\n",
       "         -0.9333,  0.9257, -0.3836, -0.1517],\n",
       "        [ 0.3209,  1.3938,  1.5060, -0.5414,  0.2553, -0.3046,  0.3209,\n",
       "          1.3938,  1.5060, -0.5414,  0.2553, -0.3046,  0.3209,  1.3938,\n",
       "          1.5060, -0.5414,  0.2553, -0.3046],\n",
       "        [ 0.8174, -0.0053, -1.9132, -0.6616, -0.2398, -0.0526,  0.8174,\n",
       "         -0.0053, -1.9132, -0.6616, -0.2398, -0.0526,  0.8174, -0.0053,\n",
       "         -1.9132, -0.6616, -0.2398, -0.0526],\n",
       "        [-0.0380, -0.7001, -0.4254,  0.1148, -0.7466,  0.3746, -0.0380,\n",
       "         -0.7001, -0.4254,  0.1148, -0.7466,  0.3746, -0.0380, -0.7001,\n",
       "         -0.4254,  0.1148, -0.7466,  0.3746]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x_t, x_t, x_t), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.cat 快速說明結束"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們的建立循環結構如下。\n",
    "\n",
    "在每個迭代的開始，為了確保context_state是乾淨的，我們需要用初始化我們的context_state向量。\n",
    "\n",
    "環遍歷序列的每個元素。我們前進的方法執行返回將用於下一個步驟的預測和context_state的前向傳遞。然後我們計算均方誤差（MSE），當我們想要預測連續值時，這是一個自然的選擇。通過在損失上運行backward（）方法我們計算梯度，然後我們更新權重。我們應該通過調用zero_（）方法清除每次迭代的漸變，否則將累積漸變。我們做的最後一件事是將context_state向量包裝在新的Variable中，以將其從歷史記錄中分離出來。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7022e355ebfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#依序將0.9093、0.6755取出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#依序將0.6755、0.3350、-0.0584、-0.4425取出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#實際-預測 計算Loss MSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-33fa4ee5c6bf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, context_state, w1, w2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mxh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#將input與context_state做連接，並成為列(Row)呈現\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mcontext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#先對w1作內積，相近的數值就接近，再轉換tanh收斂到-1~1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#再對w2做內積作為輸出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#回傳context_state與out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "  total_loss = 0\n",
    "  #裝RNN的資料context_state\n",
    "  context_state = Variable(torch.zeros((1, hidden_size)).type(dtype), requires_grad=True)\n",
    "    #起始為0  0  0  0  0  0 因為hidden_size設定為6\n",
    "  for j in range(x.size(0)): #x.size(0)確保是正確數字\n",
    "    input = x[j:(j+1)] #依序將0.9093、0.6755取出\n",
    "    target = y[j:(j+1)] #依序將0.6755、0.3350、-0.0584、-0.4425取出\n",
    "    (pred, context_state) = forward(input, context_state, w1, w2)\n",
    "    #實際-預測 計算Loss MSE\n",
    "    loss = (pred - target).pow(2).sum()/2\n",
    "    total_loss += loss\n",
    "    loss.backward()\n",
    "    #加上學習速率，加得越大數值跳越快，權重重新產生\n",
    "    w1.data -= lr * w1.grad.data \n",
    "    w2.data -= lr * w2.grad.data\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()\n",
    "    context_state = Variable(context_state.data)\n",
    "  if i % 100 == 0: #取餘數，讓他變成10次顯示一次\n",
    "     print(\"Epoch: {} loss {}\".format(i, total_loss.data[0]))\n",
    "     print(w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練期間產生的輸出顯示每個時期的損失如何減少，這是一個好兆頭。衰退損失意味著我們的模型正在學習。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一旦我們的模型被訓練，我們就可以進行預測，在序列的每個步驟中，我們將使用單個數據點為模型提供信息，並要求模型在下一個時間步驟預測一個值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_state = Variable(torch.zeros((1, hidden_size)).type(dtype), requires_grad=False)\n",
    "predictions = []\n",
    "\n",
    "for i in range(x.size(0)):\n",
    "  input = x[i:i+1]\n",
    "  (pred, context_state) = forward(input, context_state, w1, w2) #w1,w2是由上面帶下來的數值\n",
    "  context_state = context_state\n",
    "  predictions.append(pred.data.numpy().ravel()) #透過data.numpy將pred轉numpy,透過數據ravel整理一下\n",
    "  #print(\"predictions==========\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niUFERGIoMYiISIz/D+3CQphNwLDJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data_time_steps為x軸,x.data.numpy為Y軸\n",
    "pl.scatter(data_time_steps[:-1], x.data.numpy(), s=90, label=\"Actual\") # s= 圈圈大小\n",
    "pl.scatter(data_time_steps[1:], predictions, label=\"Predicted\")\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
